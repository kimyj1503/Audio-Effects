{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimyj1503/Audio-Effects/blob/master/ProteusCapture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# GuitarML Proteus Capture Instructions\n",
        "-------------\n",
        "You will need the \"ProteusCapture.wav\" file to re-amp your gear. You can download this audio file here: [ProteusCapture.wav](https://github.com/GuitarML/Automated-GuitarAmpModelling/raw/proteus-capture/Data/Proteus_Capture.wav).\n",
        "\n",
        "Reamp your pedal, amp, or rig by running this audio signal through your device and record the output. For best results, use a reamp box for pedals and a loadbox for amps (using a mic for amps is also an option). Render the new recording as a WAV file. **Please use 44.1kHz, 16-bit PCM, mono.**\n",
        "Video tutorials are available on [Youtube](https://youtu.be/86oQuYHjpy0).\n",
        "\n",
        "-------------\n",
        "\n",
        "#####  **Step 1**. Click \"Runtime\" in the Colab top menu bar, then \"Change Runtime Type\" and select \"GPU\" and save. You have a limited number of consecutive GPU hours with the free version of Colab, but this will reset in a day or so.\n",
        "\n",
        "#####  **Step 2**. Upload your recorded output from your device by dragging and dropping the \"out.wav\" file to the file browser in the left hand window in Colab. Ensure that this file is named \"out.wav\" for snapshot models. Parameterized capture of a knob requires 5 separate .wav output files, named:\n",
        "       \"out1.wav\", \"out2.wav\", \"out3.wav\", \"out4.wav\", \"out5.wav\"\n",
        "\n",
        "##### **Step 3**. Run the SETUP ENVIRONMENT section by clicking the run arrow on the top left of the box. This should take less than a minute.\n",
        "\n",
        "##### **Step 4**. Choose one (and only one) of the next 4 options as applicable to your captured device. This will begin the model training process. It should take about 10 minutes with GPU runtime selected. The training may finish before reaching 300 epochs, this is normal. Parameterized capture of a full knob will take significantly longer, 30+ minutes.\n",
        "        \n",
        "##### **Step 5**. Run this section to generate a Proteus compatible model file. Download from the left hand file browser by right clicking the \"newProteusModel.json\" filename in the left hand menu and selecting \"Download\". May need to refresh the filebrowser by clicking the refresh folder icon.\n",
        "\n",
        "##### **Step 6**. Optionally, generate a plot of the signals to visually see how close the model is to the actual device.\n",
        "\n",
        "------------\n",
        "**Note**: Recommended to \"Disconnect and delete runtime\" from the \"Runtime\" menu and \"Reconnect\" to reset the environment\n",
        "when training additional models. Make sure to download your trained model before disconnecting.\n",
        "\n",
        "**Note**: To continue to refine the model, you may run the same Step 4 (a,b,c) after changing the \"-eps\" field to the number of epochs to continue training. For example, in Step 4c., change \"-eps 300\" to \"-eps 100\" to run an additional 100 epochs. Then re-run Step 5 to generate a new Proteus compatible model.\n"
      ],
      "metadata": {
        "id": "ChdrlGCt7qhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "### **STEP 3** : SETUP ENVIRONMENT\n",
        "###### Run this block to setup environment. May take a few minutes. Only run this once per Colab session."
      ],
      "metadata": {
        "id": "T0YQxFKX8toq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GuitarML/Automated-GuitarAmpModelling.git\n",
        "%cd Automated-GuitarAmpModelling/\n",
        "!git checkout proteus-capture\n",
        "!git submodule update --init --recursive\n",
        "!pip install torch==2.3.0 # This is a work-around for the breaking changes in pytorch 2.4.0, please allow a few extra minutes for reinstalling dependencies"
      ],
      "metadata": {
        "id": "pzrdkYdTd3cX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317fe178-9fb9-490e-ce91-24c5d9854dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Automated-GuitarAmpModelling'...\n",
            "remote: Enumerating objects: 644, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 644 (delta 104), reused 88 (delta 86), pack-reused 507 (from 1)\u001b[K\n",
            "Receiving objects: 100% (644/644), 168.95 MiB | 19.83 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n",
            "Updating files: 100% (66/66), done.\n",
            "/content/Automated-GuitarAmpModelling\n",
            "Branch 'proteus-capture' set up to track remote branch 'proteus-capture' from 'origin'.\n",
            "Switched to a new branch 'proteus-capture'\n",
            "Submodule 'CoreAudioML' (https://github.com/GuitarML/CoreAudioML) registered for path 'CoreAudioML'\n",
            "Cloning into '/content/Automated-GuitarAmpModelling/CoreAudioML'...\n",
            "Submodule path 'CoreAudioML': checked out '0831965db63add6498c1849f757a95e6c3c81f33'\n",
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "### **STEP 4d**.  Run this to start capture of a Knob/Control on your amp or pedal (Parameterized Capture)\n",
        "######           This requires 5 separate recordings from a Gain or EQ knob at 5 equal steps, using the Proteus_Capture.wav as input. For example: 0% (or just above 0%), 25%, 50%, 75%, 100% You must upload your five .wav files and re-name them:\n",
        "               \"out1.wav\", \"out2.wav\", \"out3.wav\", \"out4.wav\", \"out5.wav\""
      ],
      "metadata": {
        "id": "5Q7lBR879LQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"proteus_knob\"\n",
        "!python prep_wav2.py $model -p \"./Configs/Parameterization-Config-Proteus.json\" --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -is 2 -eps 300"
      ],
      "metadata": {
        "id": "8MYDHLNWt64F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "### **STEP 5**. After Above Capture Process is Completed, Run this to generate a Proteus compatible model file.\n",
        "######The model file will be located in the top level folder with the name \"newProteusModel.json\" May need to refresh the left hand file browser by clicking the refresh folder icon. Right click the file and choose download, then rename as appropriate.\n"
      ],
      "metadata": {
        "id": "ijHoiPKW9cnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cp \"Results/\"$model\"-RNN3-\"$model\"/model_best.json\" ../newProteusModel.json"
      ],
      "metadata": {
        "id": "j4ypBZrXi5jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "### **STEP 6**. (Optional) After above Capture Process is completed, Run this to generate graphs of the device model\n",
        "######         The PNG image will be located in the top level folder with the name \"detail_signal_comparison_e2s...\". May need to refresh the left hand file browser by clicking the refresh folder icon. Double click the PNG file to view the graphs. These graphs show approximately 10 milliseconds of audio signal. The top plot shows the input signal. The middle plot shows the target device signal vs the signal predicted by the new model. The goal is for these signals to be as close as possible."
      ],
      "metadata": {
        "id": "ZA_LO7ZV9ovd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python plot.py $model\n",
        "%cp \"Results/\"$model\"-RNN3-\"$model\"/\"$model\"_Detail\"* ../"
      ],
      "metadata": {
        "id": "Z2u4IKm_d3Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "### TROUBLESHOOTING NOTES\n",
        "\n",
        "1. Training will go through 300 epochs, beginning with a pre-trained starting point model. The number of epochs can be adjusted by changing the \"-eps\" value in the dist_model_recnet.py line on step 4 (a,b,c,d). You can run the same training step again to refine the model, and stop at any time.\n",
        "\n",
        "2. This capture method is limited to non-time based effects (no Delay, Reverb, Flange, Phaser, etc.) It is intended for Amplifiers, Distortion, Overdrive, Boost, Preamps. Results on Compressors vary. The same rules apply for capturing a plugin or other digital audio effect.\n",
        "\n",
        "3. For ideal amplifier capture, record the direct out signal from a load box. Recommended to use a re-amp device when playing the ProteusCapture.wav out of your audio device for impedence matching.\n",
        "\n",
        "4. The final loss values during training should be less than 0.08 to be considered successful. A loss of 0.02 or less is ideal. Higher than 0.10 indicates difficulty in training a model from the device, but note that mic'd amps will typically have a higher loss due to the complexities of the cab/mic. If the loss remains at 0.75 or higher, this could indicate a problem with the out.wav file, either from audio misalignment or error during the upload to Colab. If the latency in your recording is too high (more than 3 milliseconds) use the click around 1 second into the capture WAV to line up your out.wav in your DAW.\n",
        "\n",
        "5. For Parameterized Capture of an amp or pedal knob, if the device knob at 0% means there is no volume out of your device (such as a gain knob on an amplifier), then you should raise it slightly until your hear volume out. The model training doesn't do well if one of the 5 steps is silent.\n",
        "\n",
        "6. Email \"smartguitarml@gmail.com\" for troubleshooting help, or to share Proteus models to add to the ToneLibrary."
      ],
      "metadata": {
        "id": "U5KY3ObN9vfs"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}